{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "negative-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "def print_full(x):\n",
    "    try:\n",
    "        v = len(x)\n",
    "    except:\n",
    "        v = 1000000\n",
    "    pd.set_option('display.max_rows', v)\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('uncleaned-data.csv', 'r', encoding='utf8')\n",
    "df = pd.read_csv(file, dtype={\n",
    "    \"id\": \"string\",\n",
    "    \"age\": \"string\",\n",
    "    \"city\": \"string\",\n",
    "    \"sex\": \"category\",\n",
    "    \"province\": \"string\",\n",
    "    \"country\": \"string\",\n",
    "    \"latitude\": float,\n",
    "    \"longitude\": float,\n",
    "    \"geo_resolution\": \"category\",\n",
    "    \"date_onset_symptoms\": \"string\",\n",
    "    \"date_admission_hospital\": \"string\",\n",
    "    \"date_confirmation\": \"string\",\n",
    "    \"symptoms\": \"string\",\n",
    "    \"travel_history_dates\": \"string\",\n",
    "    \"travel_history_location\": \"string\",\n",
    "    \"reported_market_exposure\": \"category\",\n",
    "    \"additional_information\": \"string\",\n",
    "    \"chronic_disease_binary\": \"string\",\n",
    "    \"chronic_disease\": \"string\",\n",
    "    \"source\": \"string\",\n",
    "    \"sequence_available\": \"category\",\n",
    "    \"outcome\": \"string\",\n",
    "    \"date_death_or_discharge\": \"string\",\n",
    "    \"notes_for_discussion\": \"string\",\n",
    "    \"location\": \"string\",\n",
    "    \"admin3\": \"string\",\n",
    "    \"admin2\": \"string\",\n",
    "    \"admin1\": \"string\",\n",
    "    \"country_new\": \"string\",\n",
    "    \"admin_id\": \"Int64\",\n",
    "    \"data_moderator_initials\": \"string\",\n",
    "    \"chronic_disease_binary\": bool,\n",
    "    \"lives_in_Wuhan\": \"string\",\n",
    "    \"travel_history_binary\": \"boolean\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['travel_history_binary'] = df['travel_history_binary'].fillna(value=False).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lives_in_Wuhan'] = df['lives_in_Wuhan'].replace(['yes', 'no', pd.NA], [True, False, False]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['ID', 'admin_id', 'source', 'admin1', 'admin2', 'admin3', 'data_moderator_initials', 'notes_for_discussion', 'location', 'country_new'], axis='columns')\n",
    "\n",
    "# Remove columns that *could* be useful if the data was less sparse/more relevant to my project\n",
    "df = df.drop(['date_death_or_discharge'], axis='columns')\n",
    "df = df.drop(['additional_information'], axis='columns')\n",
    "df = df.drop(['reported_market_exposure'], axis='columns')\n",
    "df = df.drop(['city', 'province', 'country'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "domestic-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all_with(df1, col, items, rep):\n",
    "    df1[col] = df1[col].replace(items, [rep] * len(items))\n",
    "    return df1\n",
    "\n",
    "df = replace_all_with(df, 'outcome', ['recovered', 'Alive', 'not hospitalized', 'recovering at home 03.03.2020'], 'Recovered')\n",
    "df = replace_all_with(df, 'outcome', ['Stable', 'Discharged', 'discharge', 'discharged', 'Discharged from hospital', 'Migrated', 'Migrated_Other', 'Symptoms only improved with cough. Currently hospitalized for follow-up.'], 'Recovered (hospitalized)')\n",
    "df = replace_all_with(df, 'outcome', ['Death', 'Died', 'Dead', 'dead', 'death', 'died'], 'Deceased')\n",
    "df = replace_all_with(df, 'outcome', ['https://www.mspbs.gov.py/covid-19.php', 'released from quarantine'], pd.NA)\n",
    "df = replace_all_with(df, 'outcome', ['stable condition', 'stable', 'Under treatment', 'Receiving Treatment',], 'Hospitalized')\n",
    "df = replace_all_with(df, 'outcome', ['severe', 'unstable', 'severe illness', 'critical condition, intubated as of 14.02.2020', 'critical condition', 'treated in an intensive care unit (14.02.2020)'], 'Critical condition')\n",
    "\n",
    "df = df.dropna(how='any', subset=['outcome'])\n",
    "\n",
    "df['outcome'] = df['outcome'].astype('category')\n",
    "category_dict = dict(enumerate(df['outcome'].cat.categories))\n",
    "df['outcome'] = df['outcome'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: 'Critical condition',\n",
       " 1: 'Deceased',\n",
       " 2: 'Hospitalized',\n",
       " 3: 'Recovered',\n",
       " 4: 'Recovered (hospitalized)'}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequence_available_binary'] = df['sequence_available'].replace([pd.NA, 'yes, BetaCoV/Mexico/CDMX/InDRE_01/2020', 'yes', '28.02.2020', '02.03.2020', '10.03.2020'], [False, True, True, True, True, True]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].cat.codes\n",
    "df['geo_resolution'] = df['geo_resolution'].cat.codes\n",
    "df['sequence_available'] = df['sequence_available'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df['age'].str.replace(r'(\\d+) (month|week)s?', '0', regex=True)\n",
    "df = df.combine_first(df['age'].str.extract(r'^(?P<age_min>\\d?\\.?\\d+)\\s*-?\\s*(?P<age_max>\\d+)?$')).drop(['age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_max'] = np.where(df['age_max'].isnull(), df['age_min'], df['age_max'])\n",
    "\n",
    "df = df.fillna(value={\n",
    "    'age_min': '-1',\n",
    "    'age_max': '-1'\n",
    "})\n",
    "\n",
    "df['age_min'] = df['age_min'].astype('float')\n",
    "df['age_max'] = df['age_max'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_col_to_days_since(series, since, invert=False, impute= -1):\n",
    "    if not invert:\n",
    "        v = series - since\n",
    "    else:\n",
    "        v = since - series\n",
    "    \n",
    "    v = v.dt.days\n",
    "    v = v.fillna(value=impute)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.combine_first(df['date_confirmation'].str.extract(r'^(?P<date_confirmation_min>\\d+\\.\\d+\\.\\d+)\\s*-?\\s*(?P<date_confirmation_max>\\d+\\.\\d+\\.\\d+)?$')).drop(['date_confirmation'], axis=1)\n",
    "df['date_confirmation_max'] = np.where(df['date_confirmation_max'].isnull(), df['date_confirmation_min'], df['date_confirmation_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['date_confirmation_min', 'date_confirmation_max']] = df[['date_confirmation_min', 'date_confirmation_max']].apply(pd.to_datetime)\n",
    "\n",
    "df['ds_date_confirmation_min'] = convert_col_to_days_since(df['date_confirmation_min'], df['date_confirmation_min'].min())\n",
    "df['ds_date_confirmation_max'] = convert_col_to_days_since(df['date_confirmation_max'], df['date_confirmation_min'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[~pd.isnull(df['date_onset_symptoms'])][['date_confirmation', 'date_onset_symptoms']]\r\n",
    "\r\n",
    "df['date_onset_symptoms'] = df['date_onset_symptoms'].replace(['01.01.2020-12.01.2020'], ['06.01.2020'])\r\n",
    "df['date_onset_symptoms'] = pd.to_datetime(df['date_onset_symptoms'])\r\n",
    "\r\n",
    "df['ds_date_onset_symptoms'] = convert_col_to_days_since(df['date_onset_symptoms'], df['date_confirmation_min'], invert=True, impute=0)\r\n",
    "df = df.drop(['date_onset_symptoms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_admission_hospital'] =  pd.to_datetime(df['date_admission_hospital'])\n",
    "\n",
    "df['ds_date_admission_hospital'] = convert_col_to_days_since(df['date_admission_hospital'], df['date_confirmation_min'], invert=True, impute=0)\n",
    "df = df.drop(['date_admission_hospital'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['date_confirmation_min', 'date_confirmation_max'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['travel_history_dates'].str.extract(r'(?P<date_enter_Wuhan>\\d+\\.\\d+\\.\\d+)?\\s*-?\\s*(?=(?P<date_exit_Wuhan>\\d+\\.\\d+\\.\\d+))')], axis=1)\n",
    "df = df.drop(['travel_history_dates'], axis=1)\n",
    "\n",
    "df['date_enter_Wuhan'] = pd.to_datetime(df['date_enter_Wuhan'])\n",
    "df['date_exit_Wuhan'] = pd.to_datetime(df['date_exit_Wuhan'])\n",
    "df['time_in_Wuhan'] = abs((df[~pd.isnull(df['date_exit_Wuhan'])]['date_exit_Wuhan'] - df['date_enter_Wuhan']).dt.days)\n",
    "df['time_in_Wuhan'] = np.where(pd.isnull(df['time_in_Wuhan']) & ~pd.isnull(df['date_exit_Wuhan']), df['time_in_Wuhan'].mean(), df['time_in_Wuhan'])\n",
    "\n",
    "df['time_in_Wuhan'] = df['time_in_Wuhan'].fillna(value=0)\n",
    "df = df.drop(['date_enter_Wuhan', 'date_exit_Wuhan'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a row that contains a location under chronic_disease since it's likely bad data entry\n",
    "df = df[~df['chronic_disease'].str.contains(r'Iran', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chronic_disease'] = df['chronic_disease'].str.lower()\n",
    "df['chronic_disease'] = df['chronic_disease'].str.replace(r'(:|;)', \",\", regex=True)\n",
    "df['chronic_disease'] = df['chronic_disease'].str.replace(r'(history of hypertension|hypertension for more than 20 years|hypertenstion|hypertensive)', 'hypertension', regex=True)\n",
    "df['chronic_disease'] = df['chronic_disease'].str.replace('copd', 'chronic obstructive pulmonary disease')\n",
    "df['chronic_disease'] = df['chronic_disease'].str.replace('diabetes for more than 20 years', 'diabetes')\n",
    "\n",
    "df = pd.concat([df, df['chronic_disease'].str.get_dummies(sep=',').add_prefix('chronic_disease_')], axis=1).drop('chronic_disease', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['symptoms'] = df['symptoms'].str.lower()\n",
    "df['symptoms'] = df['symptoms'].str.replace(r'(:|;)', \",\", regex=True)\n",
    "df = df[~df['symptoms'].str.contains('none', na=False)]\n",
    "\n",
    "df = pd.concat([df, df['symptoms'].str.get_dummies(sep=',').add_prefix('symptoms_')], axis=1).drop('symptoms', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['travel_history_location'] = df['travel_history_location'].str.lower()\n",
    "df['travel_history_location'] = df['travel_history_location'].str.replace(r'(:|;)', \",\", regex=True)\n",
    "df = pd.concat([df, df['travel_history_location'].str.get_dummies(sep=',').add_prefix('travel_history_includes_')], axis=1).drop('travel_history_location', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cultural-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('./processed-data.pkl')\n",
    "df.to_csv('./processed-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}